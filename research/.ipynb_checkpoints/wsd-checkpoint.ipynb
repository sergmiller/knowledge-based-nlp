{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Extract definitions for all senses-candidates from WordNet (via nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_file = '../WSD_Evaluation_Framework/Data_Validation/candidatesWN30.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_candidates(file):\n",
    "    kv = defaultdict(list)\n",
    "    wn_ids = set()\n",
    "    with open(file) as f:\n",
    "        for line in tqdm(f,position=0):\n",
    "            s = line[:-1].split('\\t')\n",
    "            assert len(s) >= 3 and s[1] in ['v','a','n','r']\n",
    "            kv[(s[0],s[1])] = s[2:]\n",
    "            for t in s[2:]:\n",
    "                wn_ids.add(t)\n",
    "    return kv, wn_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155287it [00:00, 169445.94it/s]\n"
     ]
    }
   ],
   "source": [
    "w_t2wn, wn_id_set = read_candidates(candidates_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155287, 206941)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_t2wn), len(wn_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1000000000000%1:23:01::', '1000000000000%1:23:00::']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_t2wn[('1000000000000', 'n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155287/155287 [00:03<00:00, 44894.26it/s]\n"
     ]
    }
   ],
   "source": [
    "wn2definition = defaultdict(str)\n",
    "wn2examples = defaultdict(list)\n",
    "\n",
    "for k in tqdm(w_t2wn.keys(), position=0):\n",
    "    candidates = wn.synsets(k[0])\n",
    "    assert len(candidates) > 0\n",
    "    for c in candidates:\n",
    "        for l in c.lemmas():\n",
    "            wn_id = l.key()  # something like shuffle%1:04:00::\n",
    "            if wn_id in wn_id_set:\n",
    "                wn2definition[wn_id] = c.definition()  # sentence(str)\n",
    "                if len(c.examples()) > 0:\n",
    "                    wn2examples[wn_id] = c.examples()  # list of sentences (save all of them just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206941, 59634)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn2sense), len(wn2examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155287/155287 [00:01<00:00, 147903.07it/s]\n"
     ]
    }
   ],
   "source": [
    "w_t2wn_definition_examples = defaultdict(list)\n",
    "\n",
    "for k in tqdm(w_t2wn.keys(), position=0):\n",
    "    data = [(id, wn2definition[id], wn2examples[id]) for id in w_t2wn[k]]\n",
    "    if len(data) > 0:\n",
    "        w_t2wn_definition_examples[k] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155287"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_t2wn_definition_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king%1:18:00::', 'a male sovereign; ruler of a kingdom', []),\n",
       " ('king%1:18:02::', 'a competitor who holds a preeminent position', []),\n",
       " ('king%1:18:01::',\n",
       "  'a very wealthy or powerful businessman',\n",
       "  ['an oil baron']),\n",
       " ('king%1:26:00::',\n",
       "  'preeminence in a particular category or group or field',\n",
       "  ['the lion is the king of beasts']),\n",
       " ('king%1:18:05::', 'United States woman tennis player (born in 1943)', []),\n",
       " ('king%1:18:04::',\n",
       "  'United States guitar player and singer of the blues (born in 1925)',\n",
       "  []),\n",
       " ('king%1:18:03::',\n",
       "  'United States charismatic civil rights leader and Baptist minister who campaigned against the segregation of Blacks (1929-1968)',\n",
       "  []),\n",
       " ('king%1:06:02::',\n",
       "  \"a checker that has been moved to the opponent's first row where it is promoted to a piece that is free to move either forward or backward\",\n",
       "  []),\n",
       " ('king%1:06:01::',\n",
       "  'one of the four playing cards in a deck bearing the picture of a king',\n",
       "  []),\n",
       " ('king%1:06:00::', '(chess) the weakest but the most important piece', [])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_t2wn_definition_examples[('king', 'n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle mapping (word, tag) -> [(WN_id_1, definition_1, [example_of_definition_1_1,...]), ...(WN_id_N, definition_N, [...])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('word_tag_2_wordnet_definition_examples.npy', dict(w_t2wn_definition_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Prepare WSD datasets Semeval2007, Semeval2013, Semeval2015 \n",
    "Parse xml with triplets (word, tag, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "semval7_data_file = '../WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [('lemma', 'you'), ('pos', 'PRON')]\n",
    "# [('lemma', 'oct.'), ('pos', 'NOUN')]\n",
    "# [('lemma', '6'), ('pos', 'NUM')]\n",
    "# [('lemma', 'editorial'), ('pos', 'NOUN')]\n",
    "# [('lemma', '``'), ('pos', '.')]\n",
    "# [('lemma', 'the'), ('pos', 'DET')]\n",
    "# [('lemma', 'ill'), ('pos', 'NOUN')]\n",
    "# [('lemma', 'homeless'), ('pos', 'NOUN')]\n",
    "# [('lemma', '``'), ('pos', '.')]\n",
    "# [('id', 'd000.s000.t000'), ('lemma', 'refer'), ('pos', 'VERB')]\n",
    "# [('lemma', 'to'), ('pos', 'PRT')]\n",
    "# [('id', 'd000.s000.t001'), ('lemma', 'research'), ('pos', 'NOUN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus_from_xml(file):\n",
    "\n",
    "    corpus = []\n",
    "    corpus_xml = xml.etree.ElementTree.parse(file).getroot()\n",
    "\n",
    "    for text_xml in tqdm(corpus_xml.findall('text'), position=0):\n",
    "        for sent_xml in text_xml.findall('sentence'):\n",
    "            sent = []\n",
    "            tags = []\n",
    "            target_ids = []\n",
    "            for token in sent_xml:\n",
    "                token = token.items()\n",
    "                sent.append(token[-2][1])  # \n",
    "                tags.append(str(token[-1][1][0]).lower())  # first lowercase letter of tag\n",
    "                target_ids.append(token[0][1] if len(token) > 2 else None)  #  something like d000.s000.t001 (optional)\n",
    "            corpus.append({'sentence': sent, 'tags': tags, 'target_ids': target_ids})\n",
    "            \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 959.06it/s]\n"
     ]
    }
   ],
   "source": [
    "semeval2007 = read_corpus_from_xml(semval7_datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
